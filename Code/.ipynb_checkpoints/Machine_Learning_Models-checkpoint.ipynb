{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from collections import Counter\n",
    "from path import Path\n",
    "import hvplot.pandas\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import mpu\n",
    "from uszipcode import SearchEngine\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cleaning_data_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_who_wins(starting_pitcher, opposing_pitcher, home_or_away, model):\n",
    "    \n",
    "    \n",
    "    # gathering pitching data from two inputs in the function\n",
    "    opp_pitch_class = []\n",
    "    opp_pitch_class_2 = []\n",
    "    opp_pitch_class_3 = []\n",
    "    opp_pitch_class_4 = []\n",
    "    opp_pitch_class_5 = []\n",
    "    opp_pitch_class_6 = []\n",
    "    opp_pitch_class_7 = []\n",
    "    opp_pitch_class_8 = []\n",
    "    opp_pitch_class_9 = []\n",
    "    opp_pitch_class_10 = []\n",
    "    opp_pitch_class_11 = []\n",
    "    \n",
    "    if opposing_pitcher in df_pitch.index:\n",
    "        opp_pitch_class.append(df_pitch.loc[opposing_pitcher][\"ERA\"])\n",
    "        opp_pitch_class_2.append(df_pitch.loc[opposing_pitcher][\"WHIP\"])\n",
    "        opp_pitch_class_3.append(df_pitch.loc[opposing_pitcher][\"IP\"])\n",
    "        opp_pitch_class_4.append(df_pitch.loc[opposing_pitcher][\"K\"])\n",
    "        opp_pitch_class_5.append(df_pitch.loc[opposing_pitcher][\"HR\"])        \n",
    "#         opp_pitch_class.append(df_pitch.loc[opposing_pitcher][\"ERA\"])\n",
    "#         opp_pitch_class_2.append(df_pitch.loc[opposing_pitcher][\"CG\"])\n",
    "#         opp_pitch_class_3.append(df_pitch.loc[opposing_pitcher][\"IP\"])\n",
    "#         opp_pitch_class_4.append(df_pitch.loc[opposing_pitcher][\"ERA+\"])\n",
    "#         opp_pitch_class_5.append(df_pitch.loc[opposing_pitcher][\"FIP\"])\n",
    "#         opp_pitch_class_6.append(df_pitch.loc[opposing_pitcher][\"WHIP\"])\n",
    "#         opp_pitch_class_7.append(df_pitch.loc[opposing_pitcher][\"H9\"])\n",
    "#         opp_pitch_class_8.append(df_pitch.loc[opposing_pitcher][\"HR9\"])\n",
    "#         opp_pitch_class_9.append(df_pitch.loc[opposing_pitcher][\"BB9\"])\n",
    "#         opp_pitch_class_10.append(df_pitch.loc[opposing_pitcher][\"SO9\"])\n",
    "#         opp_pitch_class_11.append(df_pitch.loc[opposing_pitcher][\"SO/W\"])\n",
    "    else:\n",
    "        print(\"Opposing Pitcher Not Found\")\n",
    "\n",
    "    \n",
    "    start_pitch_class = []\n",
    "    start_pitch_class_2 = []\n",
    "    start_pitch_class_3 = []\n",
    "    start_pitch_class_4 = []\n",
    "    start_pitch_class_5 = []\n",
    "    start_pitch_class_6 = []\n",
    "    start_pitch_class_7 = []\n",
    "    start_pitch_class_8 = []\n",
    "    start_pitch_class_9 = []\n",
    "    start_pitch_class_10 = []\n",
    "    start_pitch_class_11 = []\n",
    "       \n",
    "    if starting_pitcher in df_pitch.index:\n",
    "        start_pitch_class.append(df_pitch.loc[starting_pitcher][\"ERA\"])\n",
    "        start_pitch_class_2.append(df_pitch.loc[starting_pitcher][\"WHIP\"])\n",
    "        start_pitch_class_3.append(df_pitch.loc[starting_pitcher][\"IP\"])\n",
    "        start_pitch_class_4.append(df_pitch.loc[starting_pitcher][\"K\"])\n",
    "        start_pitch_class_5.append(df_pitch.loc[starting_pitcher][\"HR\"])        \n",
    "#         start_pitch_class.append(df_pitch.loc[starting_pitcher][\"ERA\"])\n",
    "#         start_pitch_class_2.append(df_pitch.loc[starting_pitcher][\"CG\"])\n",
    "#         start_pitch_class_3.append(df_pitch.loc[starting_pitcher][\"IP\"])\n",
    "#         start_pitch_class_4.append(df_pitch.loc[starting_pitcher][\"ERA+\"])\n",
    "#         start_pitch_class_5.append(df_pitch.loc[starting_pitcher][\"FIP\"])\n",
    "#         start_pitch_class_6.append(df_pitch.loc[starting_pitcher][\"WHIP\"])\n",
    "#         start_pitch_class_7.append(df_pitch.loc[starting_pitcher][\"H9\"])\n",
    "#         start_pitch_class_8.append(df_pitch.loc[starting_pitcher][\"HR9\"])\n",
    "#         start_pitch_class_9.append(df_pitch.loc[starting_pitcher][\"BB9\"])\n",
    "#         start_pitch_class_10.append(df_pitch.loc[starting_pitcher][\"SO9\"])\n",
    "#         start_pitch_class_11.append(df_pitch.loc[starting_pitcher][\"SO/W\"])\n",
    "    else:\n",
    "        print(\"Starting Pitcher Not Found\")    \n",
    "        \n",
    "        \n",
    "    # gathering batting metrics from pitchers' team\n",
    "    if opposing_pitcher in team_rooster.index:\n",
    "        opp_team_name = team_rooster.loc[opposing_pitcher][\"Team Name\"]\n",
    "    \n",
    "    if opp_team_name in df_bat.index:\n",
    "        opp_team_metrics = df_bat.loc[opp_team_name]\n",
    "        \n",
    "    opp_team = pd.DataFrame(opp_team_metrics)\n",
    "    opp_team = opp_team.transpose()\n",
    "    opp_team = opp_team[[\"R/G\", \"PA\", \"AB\", \"H\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "#     opp_team = opp_team[[\"BatAge\", \"LOB\"]]\n",
    "    opp_team[\"key\"] = 1\n",
    "\n",
    "    if starting_pitcher in team_rooster.index:\n",
    "        team_name = team_rooster.loc[opposing_pitcher][\"Team Name\"]\n",
    "    \n",
    "    if team_name in df_bat.index:\n",
    "        team = df_bat.loc[team_name]\n",
    "        \n",
    "    team = pd.DataFrame(team)\n",
    "    team = team.transpose()\n",
    "    team = team[[\"R/G\", \"PA\", \"AB\", \"H\", \"HR\", \"BB\", \"SO\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"TB\", \"HBP\", \"LOB\"]]\n",
    "    team.rename(columns = {\n",
    "        \"R/G\" : \"Favorite-R/G\", \n",
    "        \"PA\" : \"Favorite-PA\", \n",
    "        \"AB\" : \"Favorite-AB\", \n",
    "        \"H\" : \"Favorite-H\", \n",
    "        \"HR\" : \"Favorite-HR\",\n",
    "        \"BB\" : \"Favorite-BB\", \n",
    "        \"SO\" : \"Favorite-SO\", \n",
    "        \"BA\" : \"Favorite-BA\", \n",
    "        \"OBP\" : \"Favorite-OBP\", \n",
    "        \"SLG\" : \"Favorite-SLG\", \n",
    "        \"OPS\" : \"Favorite-OPS\", \n",
    "        \"TB\" : \"Favorite-TB\", \n",
    "        \"HBP\" : \"Favorite-HBP\", \n",
    "        \"LOB\" : \"Favorite-LOB\",\n",
    "                }, inplace=True)\n",
    "    team[\"key\"] = 1    \n",
    "    \n",
    "    \n",
    "    # gathering distance between teams\n",
    "    distance = get_home_away_distance_in_miles(team_name, opp_team_name)\n",
    "    \n",
    "    if home_or_away == \"Away\":\n",
    "        team[\"Distance\"] = distance\n",
    "    else:\n",
    "        team[\"Distance\"] = (distance * -1)\n",
    "    \n",
    "        \n",
    "    # creating a dataframe to combine all the pitching metrics    \n",
    "    pitching_metrics = pd.DataFrame(\n",
    "    {     \n",
    "        \"ERA-Starting\" : start_pitch_class,\n",
    "        \"ERA-Opposing\" : opp_pitch_class,\n",
    "        \"WHIP-Starting\" : start_pitch_class_2,\n",
    "        \"WHIP-Opposing\" : opp_pitch_class_2,\n",
    "        \"IP-Starting\" : start_pitch_class_3,\n",
    "        \"IP-Opposing\" : opp_pitch_class_3,\n",
    "        \"K-Starting\" : start_pitch_class_4,\n",
    "        \"K-Opposing\" : opp_pitch_class_4,\n",
    "        \"HR-Starting\" : start_pitch_class_5,\n",
    "        \"HR-Opposing\" : opp_pitch_class_5,        \n",
    "#         \"ERA-Starting\" : start_pitch_class,\n",
    "#         \"ERA-Opposing\" : opp_pitch_class,\n",
    "#         \"CG-Starting\" : start_pitch_class_2,\n",
    "#         \"CG-Opposing\" : opp_pitch_class_2,\n",
    "#         \"IP-Starting\" : start_pitch_class_3,\n",
    "#         \"IP-Opposing\" : opp_pitch_class_3,\n",
    "#         \"ERA+-Starting\" : start_pitch_class_4,\n",
    "#         \"ERA+-Opposing\" : opp_pitch_class_4,\n",
    "#         \"FIP-Starting\" : start_pitch_class_5,\n",
    "#         \"FIP-Opposing\" : opp_pitch_class_5,\n",
    "#         \"WHIP-Starting\" : start_pitch_class_6,\n",
    "#         \"WHIP-Opposing\" : opp_pitch_class_6,\n",
    "#         \"H9-Starting\" : start_pitch_class_7,\n",
    "#         \"H9-Opposing\" : opp_pitch_class_7,\n",
    "#         \"HR9-Starting\" : start_pitch_class_8,\n",
    "#         \"HR9-Opposing\" : opp_pitch_class_8,\n",
    "#         \"BB9-Starting\" : start_pitch_class_9,\n",
    "#         \"BB9-Opposing\" : opp_pitch_class_9,\n",
    "#         \"SO9-Starting\" : start_pitch_class_10,\n",
    "#         \"SO9-Opposing\" : opp_pitch_class_10,\n",
    "#         \"SO/W-Starting\" : start_pitch_class_11,\n",
    "#         \"SO/W-Opposing\" : opp_pitch_class_10,\n",
    "        \"key\" : 1\n",
    "    })\n",
    "    \n",
    "    \n",
    "    # creating test data to run through model\n",
    "    batting_metrics = pd.merge(team, opp_team, on='key')\n",
    "    test_data = pd.merge(batting_metrics, pitching_metrics, on=\"key\")\n",
    "#     test_data = pd.merge(opp_team, pitching_metrics, on=\"key\")\n",
    "    test_data.drop([\"key\"], axis=1, inplace = True)\n",
    "    \n",
    "    # testing to see what the results look like before running a model\n",
    "    # it works, I can comment this out\n",
    "#     result = test_data\n",
    "    \n",
    "    # running our model\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    outcome = predictions[0]\n",
    "    \n",
    "    if outcome > 0:\n",
    "        print(\"Astros will win!\")\n",
    "    else:\n",
    "        print(\"Astros will lose. :(\")\n",
    "    #printing out our prediction\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(\"../Data/complete_dataframes/2013_2019_Astros_full.csv\"))\n",
    "df1 = pd.read_csv(Path(\"../Data/complete_dataframes/2013_2019_Astros_50_125.csv\"))\n",
    "df2 = pd.read_csv(Path(\"../Data/complete_dataframes/2013_2019_Astros_75_onwards.csv\"))\n",
    "df3 = pd.read_csv(Path(\"../Data/complete_dataframes/2013_2019_Astros_75_130.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(inplace = True)\n",
    "df1.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pitch = pd.read_csv(Path(\"../Data/pitching_data/pitch_2020.csv\"))\n",
    "df_pitch = clean_pitching_data(df_pitch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bat = pd.read_csv(Path(\"../Data/batting_data/batting_2019.csv\"))\n",
    "df_bat = clean_batting_data(df_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "X.drop([\"Result\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y = df[\"Result\"].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "In [9]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.copy()\n",
    "X.drop([\"Result\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y = df1[\"Result\"].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.copy()\n",
    "X.drop([\"Result\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y = df2[\"Result\"].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.copy()\n",
    "X.drop([\"Result\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "y = df3[\"Result\"].ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "model_1 = BalancedRandomForestClassifier(random_state=1)\n",
    "model_1.fit(X_train, y_train)\n",
    "predictions = model_1.predict(X_test)\n",
    "BalancedRandomForestClassifer_f1 = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_2 = tree.DecisionTreeClassifier()\n",
    "model_2.fit(X_train, y_train)\n",
    "predictions = model_2.predict(X_test)\n",
    "DecisionTreeClassifier_f1 = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_3 = XGBClassifier()\n",
    "model_3.fit(X_train, y_train)\n",
    "y_pred = model_3.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "XGBClassifier_f1 = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_4 = KNeighborsClassifier()\n",
    "model_4.fit(X_train,y_train)\n",
    "predictions = model_4.predict(X_test)\n",
    "KNeighborsClassifier_f1 = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_5 = LogisticRegression(solver = \"newton-cg\", random_state = 78,  max_iter = 1000000)\n",
    "model_5.fit(X_train,y_train)\n",
    "predictions = model_5.predict(X_test)\n",
    "LogisticRegression_f1_newton = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_6 = LogisticRegression(solver = \"lbfgs\", random_state = 78,  max_iter = 1000000)\n",
    "model_6.fit(X_train,y_train)\n",
    "predictions = model_6.predict(X_test)\n",
    "LogisticRegression_f1_lbfgs = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_7 = LogisticRegression(solver = \"saga\", random_state = 78,  max_iter = 1000000)\n",
    "model_7.fit(X_train,y_train)\n",
    "predictions = model_7.predict(X_test)\n",
    "LogisticRegression_f1_saga = f1_score(y_test, predictions, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_8 = LogisticRegression(solver = \"liblinear\", random_state = 78,  max_iter = 1000000)\n",
    "model_8.fit(X_train,y_train)\n",
    "predictions = model_8.predict(X_test)\n",
    "LogisticRegression_f1_liblinear = f1_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"KNeighbors CLassifier Model\",\n",
    "        \"XGBClassifier Model\",\n",
    "        \"Decision Tree Classifier Model\",\n",
    "        \"Balanced Random Forest Classifier Model\",\n",
    "        \"Logistic Regression Model LBFGS Solver\",\n",
    "        \"Logistic Regression Model Saga Solver\",\n",
    "        \"Logistic Regression Model Liblinear Solver\",\n",
    "         \"Logistic Regression Model Newton CG Solver\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [KNeighborsClassifier_f1,\n",
    "            XGBClassifier_f1,\n",
    "            DecisionTreeClassifier_f1,\n",
    "            BalancedRandomForestClassifer_f1,\n",
    "            LogisticRegression_f1_lbfgs,\n",
    "            LogisticRegression_f1_saga,\n",
    "            LogisticRegression_f1_liblinear,\n",
    "            LogisticRegression_f1_newton]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = pd.DataFrame({\"Models\" : models,\n",
    "                         \"F-1 Scores\" : f1_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores.sort_values(\"F-1 Scores\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores.hvplot.barh(x=\"Models\", y=\"F-1 Scores\", figsize = (20,10), title = \"F-1 Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Filename = \"baseball_model_1.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_1, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_2.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_2, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_3.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_3, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_4.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_4, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_5.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_5, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_6.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_6, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_7.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_7, file)\n",
    "\n",
    "    \n",
    "Model_Filename = \"baseball_model_8.pkl\"  \n",
    "\n",
    "with open(Model_Filename, 'wb') as file:  \n",
    "    pickle.dump(model_8, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Twins Game 1 September 29th, 2020\n",
    "determine_who_wins(\"Zack Greinke\", \"Kenta Maeda\", \"Away\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Twins Game 2 September 30th, 2020\n",
    "determine_who_wins(\"Jose Urquidy\", \"Jose Berrios\", \"Away\", model_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Athletics Game 1 October 5th, 2020\n",
    "determine_who_wins(\"Lance McCullers\", \"Chris Bassitt\", \"Away\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Athletics Game 2 October 6th, 2020\n",
    "determine_who_wins(\"Framber Valdez\", \"Sean Manaea\", \"Away\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Athletics Game 3 October 7th, 2020\n",
    "determine_who_wins(\"Jose Urquidy\", \"Jesus Luzardo\", \"Home\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Athletics Game 4 October 8th, 2020\n",
    "determine_who_wins(\"Zack Greinke\", \"Frankie Montas\", \"Home\", model_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 1 October 11th, 2020\n",
    "determine_who_wins(\"Framber Valdez\", \"Blake Snell\", \"Away\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 2 October 12th, 2020\n",
    "determine_who_wins(\"Lance McCullers\", \"Charlie Morton\", \"Away\", model_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 3 October 13th, 2020\n",
    "determine_who_wins(\"Jose Urquidy\", \"Ryan Yarbrough\", \"Home\", model_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 4 October 14th, 2020\n",
    "determine_who_wins(\"Zack Greinke\", \"Tyler Glasnow\", \"Home\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 5 October 15th, 2020\n",
    "determine_who_wins(\"Luis Garcia\", \"John Curtiss\", \"Home\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 6 October 16th, 2020\n",
    "determine_who_wins(\"Framber Valdez\", \"Blake Snell\", \"Away\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astros vs Rays Game 7 October 17th, 2020\n",
    "determine_who_wins(\"Lance McCullers\", \"Charlie Morton\", \"Away\", model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
